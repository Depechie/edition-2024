# Beyond text-only LLMs: unlocking multimodality with Mistral AI

## Description

Les Large language models (LLMs) sont devenus des outils essentiels pour extraire des connaissances à partir de textes. Cependant, de nombreux cas d'utilisation nécessitent de comprendre le contenu et la signification des images, des diagrammes ou des figures. Pour exploiter pleinement ces données mixtes, il est nécessaire d'étendre les capacités des LLMs au domaine multimodal.

Dans cette présentation, nous explorerons le dernier modèle multimodal de Mistral, en examinant comment il a été développé, ses mécanismes sous-jacents, ainsi que les applications pratiques qu'il permet en combinant des entrées texte et image. Cette session est conçue pour offrir aux développeurs une compréhension complète de l'architecture du modèle et de ses cas d'utilisation potentiels.

## Speakers

- [Speaker Name](https://x.com/speaker_x_handle)
- [Speaker LinkedIn](https://linkedin.com/in/speaker_linkedin_handle)
- [Speaker Company](https://speaker_company_url)
